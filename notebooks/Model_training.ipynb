{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML Model Evaluation with Cross-Validation\n",
        "\n",
        "This notebook evaluates multiple regression models using cross-validation to predict wellness scores based on Sleep, Steps, and Mood features. We'll compare three models:\n",
        "\n",
        "**Random Forest Regression**\n",
        "\n",
        "**Linear Regression**\n",
        "\n",
        "**Ridge Regression**\n"
      ],
      "metadata": {
        "id": "uXRE5DEEuMvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Required Libraries"
      ],
      "metadata": {
        "id": "y_gTpoZmuWKw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yIYPmwhbseAz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Initial Exploration\n",
        "\n",
        "Load the wellness dataset and examine its basic properties including shape, target variable range, and statistics."
      ],
      "metadata": {
        "id": "0emF_MXauhqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your labeled dataset\n",
        "df = pd.read_csv(\"/content/WellnessScores.csv\")  # Replace with actual path if needed\n",
        "print(f\"Dataset loaded: {df.shape[0]} samples, {df.shape[1]} features\")\n",
        "\n",
        "# Features and target\n",
        "X = df[['Sleep', 'Steps', 'Mood']]\n",
        "y = df['Wellness_Score']\n",
        "\n",
        "print(f\"Target variable range: {y.min():.2f} - {y.max():.2f}\")\n",
        "print(f\"Target variable mean: {y.mean():.2f} ± {y.std():.2f}\")\n",
        "print(f\"Feature columns: {list(X.columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDF_QFcVuZkr",
        "outputId": "cd040755-0f10-4256-ce15-87223f9093fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded: 2270 samples, 7 features\n",
            "Target variable range: 0.00 - 100.00\n",
            "Target variable mean: 70.84 ± 18.80\n",
            "Feature columns: ['Sleep', 'Steps', 'Mood']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation and Model Definition\n",
        "\n",
        "Split the data into training and testing sets, then define our three regression models with appropriate preprocessing pipelines."
      ],
      "metadata": {
        "id": "uUiq3UjVuvUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"Train/Test split: {X_train.shape[0]} train, {X_test.shape[0]} test samples\")\n",
        "\n",
        "# Define models with pipelines (for consistent preprocessing)\n",
        "models = {\n",
        "    \"Random Forest\": Pipeline([\n",
        "        ('rf', RandomForestRegressor(random_state=42, n_estimators=100))\n",
        "    ]),\n",
        "    \"Linear Regression\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('lr', LinearRegression())\n",
        "    ]),\n",
        "    \"Ridge Regression\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('ridge', Ridge(alpha=1.0))\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Cross-validation setup\n",
        "cv_folds = 5\n",
        "scoring_metrics = ['neg_mean_absolute_error', 'neg_root_mean_squared_error', 'r2']\n",
        "\n",
        "print(f\"Cross-Validation Setup:\")\n",
        "print(f\"   • Folds: {cv_folds}\")\n",
        "print(f\"   • Metrics: MAE, RMSE, R²\")\n",
        "print(f\"   • Random state: 42\")\n",
        "\n",
        "# Results storage\n",
        "results = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYXzGF6NumjF",
        "outputId": "f3d330b6-5984-41ab-b9dd-818e48d0f192"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Test split: 1816 train, 454 test samples\n",
            "Cross-Validation Setup:\n",
            "   • Folds: 5\n",
            "   • Metrics: MAE, RMSE, R²\n",
            "   • Random state: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Regression\n",
        "\n",
        "Evaluate the Random Forest model using cross-validation and holdout test set. Random Forest is an ensemble method that typically handles non-linear relationships well and is less prone to overfitting than individual decision trees."
      ],
      "metadata": {
        "id": "lESdFoSPvJiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Model Evaluation\n",
        "model_name = \"Random Forest\"\n",
        "model = models[model_name]\n",
        "\n",
        "\n",
        "print(f\"Evaluating: {model_name}\")\n",
        "\n",
        "\n",
        "# Cross-validation evaluation\n",
        "print(f\"Cross-Validation Results ({cv_folds}-fold):\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    model, X_train, y_train,\n",
        "    cv=cv_folds,\n",
        "    scoring=scoring_metrics,\n",
        "    return_train_score=False,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Extract and convert scores\n",
        "cv_mae_scores = -cv_results['test_neg_mean_absolute_error']\n",
        "cv_rmse_scores = -cv_results['test_neg_root_mean_squared_error']\n",
        "cv_r2_scores = cv_results['test_r2']\n",
        "\n",
        "# Calculate statistics\n",
        "mae_mean, mae_std = cv_mae_scores.mean(), cv_mae_scores.std()\n",
        "rmse_mean, rmse_std = cv_rmse_scores.mean(), cv_rmse_scores.std()\n",
        "r2_mean, r2_std = cv_r2_scores.mean(), cv_r2_scores.std()\n",
        "\n",
        "print(f\"MAE:  {mae_mean:.2f} ± {mae_std:.2f}\")\n",
        "print(f\"RMSE: {rmse_mean:.2f} ± {rmse_std:.2f}\")\n",
        "print(f\"R²:   {r2_mean:.3f} ± {r2_std:.3f}\")\n",
        "\n",
        "# Individual fold results\n",
        "print(f\"Individual Fold Results:\")\n",
        "print(\"Fold    MAE     RMSE    R²\")\n",
        "print(\"-\" * 30)\n",
        "for i in range(cv_folds):\n",
        "    print(f\"{i+1:>2}   {cv_mae_scores[i]:>6.2f}  {cv_rmse_scores[i]:>6.2f}  {cv_r2_scores[i]:>6.3f}\")\n",
        "\n",
        "# Holdout test set evaluation\n",
        "print(f\"Holdout Test Set Results:\")\n",
        "print(\"-\" * 32)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "test_preds = model.predict(X_test)\n",
        "\n",
        "test_mae = mean_absolute_error(y_test, test_preds)\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
        "test_r2 = r2_score(y_test, test_preds)\n",
        "\n",
        "print(f\"MAE:  {test_mae:.2f}\")\n",
        "print(f\"RMSE: {test_rmse:.2f}\")\n",
        "print(f\"R²:   {test_r2:.3f}\")\n",
        "\n",
        "# Overfitting analysis\n",
        "print(f\"Overfitting Analysis:\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "mae_diff = abs(test_mae - mae_mean)\n",
        "rmse_diff = abs(test_rmse - rmse_mean)\n",
        "r2_diff = abs(test_r2 - r2_mean)\n",
        "\n",
        "print(f\"MAE difference (CV vs Test):  {mae_diff:.2f}\")\n",
        "print(f\"RMSE difference (CV vs Test): {rmse_diff:.2f}\")\n",
        "print(f\"R² difference (CV vs Test):   {r2_diff:.3f}\")\n",
        "\n",
        "if mae_diff > mae_std * 2:\n",
        "    print(\"Warning: Potential overfitting detected (MAE)\")\n",
        "if rmse_diff > rmse_std * 2:\n",
        "    print(\"Warning: Potential overfitting detected (RMSE)\")\n",
        "if r2_diff > r2_std * 2:\n",
        "    print(\"Warning: Potential overfitting detected (R²)\")\n",
        "\n",
        "# Store results\n",
        "results[model_name] = {\n",
        "    'cv_mae': (mae_mean, mae_std),\n",
        "    'cv_rmse': (rmse_mean, rmse_std),\n",
        "    'cv_r2': (r2_mean, r2_std),\n",
        "    'test_mae': test_mae,\n",
        "    'test_rmse': test_rmse,\n",
        "    'test_r2': test_r2,\n",
        "    'cv_scores': {\n",
        "        'mae': cv_mae_scores,\n",
        "        'rmse': cv_rmse_scores,\n",
        "        'r2': cv_r2_scores\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3mPbAelu0S6",
        "outputId": "fc2313eb-11f5-40a5-90f4-219f50468f0c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating: Random Forest\n",
            "Cross-Validation Results (5-fold):\n",
            "---------------------------------------------\n",
            "MAE:  0.86 ± 0.08\n",
            "RMSE: 1.56 ± 0.30\n",
            "R²:   0.993 ± 0.002\n",
            "Individual Fold Results:\n",
            "Fold    MAE     RMSE    R²\n",
            "------------------------------\n",
            " 1     0.91    1.64   0.993\n",
            " 2     0.79    1.24   0.995\n",
            " 3     0.93    1.73   0.992\n",
            " 4     0.74    1.21   0.996\n",
            " 5     0.94    2.00   0.990\n",
            "Holdout Test Set Results:\n",
            "--------------------------------\n",
            "MAE:  0.76\n",
            "RMSE: 1.51\n",
            "R²:   0.992\n",
            "Overfitting Analysis:\n",
            "-------------------------\n",
            "MAE difference (CV vs Test):  0.10\n",
            "RMSE difference (CV vs Test): 0.05\n",
            "R² difference (CV vs Test):   0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression\n",
        "\n",
        "Evaluate the Linear Regression model. This is a simple baseline model that assumes a linear relationship between features and target. It includes StandardScaler preprocessing to handle different feature scales."
      ],
      "metadata": {
        "id": "2Fn6Ul4Yvdlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression Model Evaluation\n",
        "model_name = \"Linear Regression\"\n",
        "model = models[model_name]\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Evaluating: {model_name}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Cross-validation evaluation\n",
        "print(f\"Cross-Validation Results ({cv_folds}-fold):\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    model, X_train, y_train,\n",
        "    cv=cv_folds,\n",
        "    scoring=scoring_metrics,\n",
        "    return_train_score=False,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Extract and convert scores\n",
        "cv_mae_scores = -cv_results['test_neg_mean_absolute_error']\n",
        "cv_rmse_scores = -cv_results['test_neg_root_mean_squared_error']\n",
        "cv_r2_scores = cv_results['test_r2']\n",
        "\n",
        "# Calculate statistics\n",
        "mae_mean, mae_std = cv_mae_scores.mean(), cv_mae_scores.std()\n",
        "rmse_mean, rmse_std = cv_rmse_scores.mean(), cv_rmse_scores.std()\n",
        "r2_mean, r2_std = cv_r2_scores.mean(), cv_r2_scores.std()\n",
        "\n",
        "print(f\"MAE:  {mae_mean:.2f} ± {mae_std:.2f}\")\n",
        "print(f\"RMSE: {rmse_mean:.2f} ± {rmse_std:.2f}\")\n",
        "print(f\"R²:   {r2_mean:.3f} ± {r2_std:.3f}\")\n",
        "\n",
        "# Individual fold results\n",
        "print(f\"Individual Fold Results:\")\n",
        "print(\"Fold    MAE     RMSE    R²\")\n",
        "print(\"-\" * 30)\n",
        "for i in range(cv_folds):\n",
        "    print(f\"{i+1:>2}   {cv_mae_scores[i]:>6.2f}  {cv_rmse_scores[i]:>6.2f}  {cv_r2_scores[i]:>6.3f}\")\n",
        "\n",
        "# Holdout test set evaluation\n",
        "print(f\"Holdout Test Set Results:\")\n",
        "print(\"-\" * 32)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "test_preds = model.predict(X_test)\n",
        "\n",
        "test_mae = mean_absolute_error(y_test, test_preds)\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
        "test_r2 = r2_score(y_test, test_preds)\n",
        "\n",
        "print(f\"MAE:  {test_mae:.2f}\")\n",
        "print(f\"RMSE: {test_rmse:.2f}\")\n",
        "print(f\"R²:   {test_r2:.3f}\")\n",
        "\n",
        "# Overfitting analysis\n",
        "print(f\"Overfitting Analysis:\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "mae_diff = abs(test_mae - mae_mean)\n",
        "rmse_diff = abs(test_rmse - rmse_mean)\n",
        "r2_diff = abs(test_r2 - r2_mean)\n",
        "\n",
        "print(f\"MAE difference (CV vs Test):  {mae_diff:.2f}\")\n",
        "print(f\"RMSE difference (CV vs Test): {rmse_diff:.2f}\")\n",
        "print(f\"R² difference (CV vs Test):   {r2_diff:.3f}\")\n",
        "\n",
        "if mae_diff > mae_std * 2:\n",
        "    print(\"Warning: Potential overfitting detected (MAE)\")\n",
        "if rmse_diff > rmse_std * 2:\n",
        "    print(\"Warning: Potential overfitting detected (RMSE)\")\n",
        "if r2_diff > r2_std * 2:\n",
        "    print(\"Warning: Potential overfitting detected (R²)\")\n",
        "\n",
        "# Store results\n",
        "results[model_name] = {\n",
        "    'cv_mae': (mae_mean, mae_std),\n",
        "    'cv_rmse': (rmse_mean, rmse_std),\n",
        "    'cv_r2': (r2_mean, r2_std),\n",
        "    'test_mae': test_mae,\n",
        "    'test_rmse': test_rmse,\n",
        "    'test_r2': test_r2,\n",
        "    'cv_scores': {\n",
        "        'mae': cv_mae_scores,\n",
        "        'rmse': cv_rmse_scores,\n",
        "        'r2': cv_r2_scores\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY1DPVbbvP0r",
        "outputId": "604be842-7996-4c11-d77e-981aefff4737"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Evaluating: Linear Regression\n",
            "============================================================\n",
            "Cross-Validation Results (5-fold):\n",
            "---------------------------------------------\n",
            "MAE:  8.74 ± 0.31\n",
            "RMSE: 13.18 ± 0.94\n",
            "R²:   0.523 ± 0.053\n",
            "Individual Fold Results:\n",
            "Fold    MAE     RMSE    R²\n",
            "------------------------------\n",
            " 1     8.99   13.78   0.492\n",
            " 2     8.16   11.47   0.570\n",
            " 3     8.91   14.16   0.433\n",
            " 4     8.67   12.99   0.555\n",
            " 5     8.98   13.51   0.565\n",
            "Holdout Test Set Results:\n",
            "--------------------------------\n",
            "MAE:  9.26\n",
            "RMSE: 14.16\n",
            "R²:   0.326\n",
            "Overfitting Analysis:\n",
            "-------------------------\n",
            "MAE difference (CV vs Test):  0.51\n",
            "RMSE difference (CV vs Test): 0.98\n",
            "R² difference (CV vs Test):   0.197\n",
            "Warning: Potential overfitting detected (R²)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ridge Regression\n",
        "\n",
        "Evaluate the Ridge Regression model. Ridge regression adds L2 regularization to linear regression, which helps prevent overfitting by penalizing large coefficient values. This is particularly useful when dealing with multicollinearity or when you have limited training data."
      ],
      "metadata": {
        "id": "QnvvlxURvgaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridge Regression Model Evaluation\n",
        "model_name = \"Ridge Regression\"\n",
        "model = models[model_name]\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Evaluating: {model_name}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Cross-validation evaluation\n",
        "print(f\"Cross-Validation Results ({cv_folds}-fold):\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    model, X_train, y_train,\n",
        "    cv=cv_folds,\n",
        "    scoring=scoring_metrics,\n",
        "    return_train_score=False,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Extract and convert scores\n",
        "cv_mae_scores = -cv_results['test_neg_mean_absolute_error']\n",
        "cv_rmse_scores = -cv_results['test_neg_root_mean_squared_error']\n",
        "cv_r2_scores = cv_results['test_r2']\n",
        "\n",
        "# Calculate statistics\n",
        "mae_mean, mae_std = cv_mae_scores.mean(), cv_mae_scores.std()\n",
        "rmse_mean, rmse_std = cv_rmse_scores.mean(), cv_rmse_scores.std()\n",
        "r2_mean, r2_std = cv_r2_scores.mean(), cv_r2_scores.std()\n",
        "\n",
        "print(f\"MAE:  {mae_mean:.2f} ± {mae_std:.2f}\")\n",
        "print(f\"RMSE: {rmse_mean:.2f} ± {rmse_std:.2f}\")\n",
        "print(f\"R²:   {r2_mean:.3f} ± {r2_std:.3f}\")\n",
        "\n",
        "# Individual fold results\n",
        "print(f\"Individual Fold Results:\")\n",
        "print(\"Fold    MAE     RMSE    R²\")\n",
        "print(\"-\" * 30)\n",
        "for i in range(cv_folds):\n",
        "    print(f\"{i+1:>2}   {cv_mae_scores[i]:>6.2f}  {cv_rmse_scores[i]:>6.2f}  {cv_r2_scores[i]:>6.3f}\")\n",
        "\n",
        "# Holdout test set evaluation\n",
        "print(f\"Holdout Test Set Results:\")\n",
        "print(\"-\" * 32)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "test_preds = model.predict(X_test)\n",
        "\n",
        "test_mae = mean_absolute_error(y_test, test_preds)\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
        "test_r2 = r2_score(y_test, test_preds)\n",
        "\n",
        "print(f\"MAE:  {test_mae:.2f}\")\n",
        "print(f\"RMSE: {test_rmse:.2f}\")\n",
        "print(f\"R²:   {test_r2:.3f}\")\n",
        "\n",
        "# Overfitting analysis\n",
        "print(f\"Overfitting Analysis:\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "mae_diff = abs(test_mae - mae_mean)\n",
        "rmse_diff = abs(test_rmse - rmse_mean)\n",
        "r2_diff = abs(test_r2 - r2_mean)\n",
        "\n",
        "print(f\"MAE difference (CV vs Test):  {mae_diff:.2f}\")\n",
        "print(f\"RMSE difference (CV vs Test): {rmse_diff:.2f}\")\n",
        "print(f\"R² difference (CV vs Test):   {r2_diff:.3f}\")\n",
        "\n",
        "if mae_diff > mae_std * 2:\n",
        "    print(\"Warning: Potential overfitting detected (MAE)\")\n",
        "if rmse_diff > rmse_std * 2:\n",
        "    print(\"Warning: Potential overfitting detected (RMSE)\")\n",
        "if r2_diff > r2_std * 2:\n",
        "    print(\"Warning: Potential overfitting detected (R²)\")\n",
        "\n",
        "# Store results\n",
        "results[model_name] = {\n",
        "    'cv_mae': (mae_mean, mae_std),\n",
        "    'cv_rmse': (rmse_mean, rmse_std),\n",
        "    'cv_r2': (r2_mean, r2_std),\n",
        "    'test_mae': test_mae,\n",
        "    'test_rmse': test_rmse,\n",
        "    'test_r2': test_r2,\n",
        "    'cv_scores': {\n",
        "        'mae': cv_mae_scores,\n",
        "        'rmse': cv_rmse_scores,\n",
        "        'r2': cv_r2_scores\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIQPXUySvjVP",
        "outputId": "53e5e097-b246-43f4-d09e-cea8ef410068"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Evaluating: Ridge Regression\n",
            "============================================================\n",
            "Cross-Validation Results (5-fold):\n",
            "---------------------------------------------\n",
            "MAE:  8.74 ± 0.31\n",
            "RMSE: 13.18 ± 0.94\n",
            "R²:   0.523 ± 0.053\n",
            "Individual Fold Results:\n",
            "Fold    MAE     RMSE    R²\n",
            "------------------------------\n",
            " 1     8.99   13.78   0.492\n",
            " 2     8.16   11.47   0.570\n",
            " 3     8.91   14.16   0.433\n",
            " 4     8.67   12.99   0.555\n",
            " 5     8.98   13.51   0.565\n",
            "Holdout Test Set Results:\n",
            "--------------------------------\n",
            "MAE:  9.26\n",
            "RMSE: 14.16\n",
            "R²:   0.326\n",
            "Overfitting Analysis:\n",
            "-------------------------\n",
            "MAE difference (CV vs Test):  0.51\n",
            "RMSE difference (CV vs Test): 0.98\n",
            "R² difference (CV vs Test):   0.197\n",
            "Warning: Potential overfitting detected (R²)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Comparison and Analysis\n",
        "\n",
        "Compare all three models side by side to identify the best performing model and analyze their relative strengths and weaknesses."
      ],
      "metadata": {
        "id": "o5SlXXlSvl3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprehensive Model Comparison\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"COMPREHENSIVE MODEL COMPARISON\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "print(f\"Cross-Validation Performance Summary:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Model\".ljust(18) + \"MAE\".ljust(12) + \"RMSE\".ljust(12) + \"R²\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for name, res in results.items():\n",
        "    mae_mean, mae_std = res['cv_mae']\n",
        "    rmse_mean, rmse_std = res['cv_rmse']\n",
        "    r2_mean, r2_std = res['cv_r2']\n",
        "\n",
        "    mae_str = f\"{mae_mean:.2f}±{mae_std:.2f}\"\n",
        "    rmse_str = f\"{rmse_mean:.2f}±{rmse_std:.2f}\"\n",
        "    r2_str = f\"{r2_mean:.3f}±{r2_std:.3f}\"\n",
        "\n",
        "    print(f\"{name:<18}{mae_str:<12}{rmse_str:<12}{r2_str}\")\n",
        "\n",
        "print(f\"Test Set Performance Summary:\")\n",
        "print(\"-\" * 40)\n",
        "print(\"Model\".ljust(18) + \"MAE\".ljust(8) + \"RMSE\".ljust(8) + \"R²\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for name, res in results.items():\n",
        "    mae_str = f\"{res['test_mae']:.2f}\"\n",
        "    rmse_str = f\"{res['test_rmse']:.2f}\"\n",
        "    r2_str = f\"{res['test_r2']:.3f}\"\n",
        "\n",
        "    print(f\"{name:<18}{mae_str:<8}{rmse_str:<8}{r2_str}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNShfCZCvnp8",
        "outputId": "52e18b72-a98c-4136-8947-db33e20e539b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "COMPREHENSIVE MODEL COMPARISON\n",
            "============================================================\n",
            "Cross-Validation Performance Summary:\n",
            "--------------------------------------------------\n",
            "Model             MAE         RMSE        R²\n",
            "--------------------------------------------------\n",
            "Random Forest     0.86±0.08   1.56±0.30   0.993±0.002\n",
            "Linear Regression 8.74±0.31   13.18±0.94  0.523±0.053\n",
            "Ridge Regression  8.74±0.31   13.18±0.94  0.523±0.053\n",
            "Test Set Performance Summary:\n",
            "----------------------------------------\n",
            "Model             MAE     RMSE    R²\n",
            "----------------------------------------\n",
            "Random Forest     0.76    1.51    0.992\n",
            "Linear Regression 9.26    14.16   0.326\n",
            "Ridge Regression  9.26    14.16   0.326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Recommendations\n",
        "\n",
        "Analyze the results to provide recommendations on the best model choice and insights for potential improvements."
      ],
      "metadata": {
        "id": "93i-jjFtvqjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Recommendations\n",
        "print(f\"MODEL RECOMMENDATIONS\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "# Find best model based on CV R² score\n",
        "best_model = max(results.keys(), key=lambda x: results[x]['cv_r2'][0])\n",
        "best_r2 = results[best_model]['cv_r2'][0]\n",
        "\n",
        "print(f\"Best performing model: {best_model}\")\n",
        "print(f\"   Cross-validation R²: {best_r2:.3f}\")\n",
        "\n",
        "# Check for overfitting in best model\n",
        "best_cv_r2_std = results[best_model]['cv_r2'][1]\n",
        "best_test_r2 = results[best_model]['test_r2']\n",
        "r2_gap = abs(best_r2 - best_test_r2)\n",
        "\n",
        "if r2_gap > best_cv_r2_std * 2:\n",
        "    print(f\"Warning: Potential overfitting detected in {best_model}\")\n",
        "    print(f\"   CV R²: {best_r2:.3f}, Test R²: {best_test_r2:.3f}\")\n",
        "    print(f\"   Consider regularization or feature engineering\")\n",
        "else:\n",
        "    print(f\"✓ {best_model} shows consistent performance\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu6YTwAIvscU",
        "outputId": "8ad3ea18-03fa-4cf1-bdce-f96320d78894"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL RECOMMENDATIONS\n",
            "-------------------------\n",
            "Best performing model: Random Forest\n",
            "   Cross-validation R²: 0.993\n",
            "✓ Random Forest shows consistent performance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the Best Performing Model\n",
        "\n",
        "Save the Random Forest model to disk using joblib for future use."
      ],
      "metadata": {
        "id": "2ByRNQNVwYDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from datetime import datetime\n",
        "\n",
        "# Get the trained Random Forest model\n",
        "rf_model = models[\"Random Forest\"]\n",
        "\n",
        "model_filename = f\"random_forest_wellness_model.pkl\"\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(rf_model, model_filename)\n",
        "\n",
        "print(f\"Random Forest model saved as: {model_filename}\")\n",
        "print(f\"Model performance summary:\")\n",
        "print(f\"  - Cross-validation R²: {results['Random Forest']['cv_r2'][0]:.3f} ± {results['Random Forest']['cv_r2'][1]:.3f}\")\n",
        "print(f\"  - Test set R²: {results['Random Forest']['test_r2']:.3f}\")\n",
        "print(f\"  - Test set MAE: {results['Random Forest']['test_mae']:.2f}\")\n",
        "\n",
        "\n",
        "# Display model parameters\n",
        "print(f\"\\nModel configuration:\")\n",
        "rf_params = rf_model.named_steps['rf'].get_params()\n",
        "key_params = ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'random_state']\n",
        "for param in key_params:\n",
        "    if param in rf_params:\n",
        "        print(f\"  - {param}: {rf_params[param]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qccSuZ7Vv7l2",
        "outputId": "00bb5727-39cc-467d-8bdd-00ba732b2d01"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest model saved as: random_forest_wellness_model.pkl\n",
            "Model performance summary:\n",
            "  - Cross-validation R²: 0.993 ± 0.002\n",
            "  - Test set R²: 0.992\n",
            "  - Test set MAE: 0.76\n",
            "\n",
            "Model configuration:\n",
            "  - n_estimators: 100\n",
            "  - max_depth: None\n",
            "  - min_samples_split: 2\n",
            "  - min_samples_leaf: 1\n",
            "  - random_state: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(model_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PFr5_cmFwcbJ",
        "outputId": "af653734-5967-480b-e6d4-98d0b3fef601"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c20ff4c9-9d03-4415-acdf-97c23f43e905\", \"random_forest_wellness_model_20250526_040353.pkl\", 14665306)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}